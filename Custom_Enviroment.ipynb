{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Intro",
   "id": "32a8ba7432811a44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The plan is to have a player blob (blue), which aims to navigate its way as quickly as possible to the food blob (green), while avoiding the enemy blob (red). Now, we could make this super smooth with high definition, but we already know we're going to be breaking it down into observation spaces. Instead, let's just start in a discrete space. Something between a 10x10 and 20x20 should suffice. Do note, the larger you go, the larger your Q-Table will be in terms of space it takes up in memory as well as time it takes for the model to actually learn. So, our environment will be a 20 x 20 grid, where we have 1 player, 1 enemy, and 1 food. For now, we'll just have the player able to move, in attempt to reach the food, which will yield a reward.",
   "id": "3052a274bf96f925"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Requirements",
   "id": "6efa40172bb572cc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f64468d7213f64fa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T12:13:37.429150Z",
     "start_time": "2024-08-07T12:13:37.417514Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from PIL import Image  # for creating visual env\n",
    "import cv2  # for showing our visual live\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle  # to save/load Q-Tables\n",
    "from matplotlib import style  # to make pretty charts.\n",
    "import time  # using this to keep track of our saved Q-Tables."
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Environment size, constants and variables\n",
    "A 10x10 Q-Table for example, in this case, is ~15MB. A 20x20 is ~195MB"
   ],
   "id": "9d8a903bda363e13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "style.use('ggplot')\n",
    "SIZE = 10\n",
    "HM_EPISODES = 25000\n",
    "MOVE_PENALTY = 1\n",
    "ENEMY_PENALTY = 300\n",
    "FOOD_REWARD = 25\n",
    "epsilon = 0.9\n",
    "EPS_DECAY = 0.9998\n",
    "SHOW_EVERY = 3000\n",
    "# In case you have a q table, load here (filename)\n",
    "start_q_table = None\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.95\n",
    "# key in dict\n",
    "PLAYER_N = 1\n",
    "FOOD_N = 2\n",
    "ENEMY_N = 3\n",
    "# Dict for colors BGR\n",
    "d = {1: (255, 175, 0),\n",
    "     2: (0,255, 0),\n",
    "     3: (0, 0, 255)}"
   ],
   "id": "969b576190b3c79f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Blob",
   "id": "e1defa8d370b4b1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T12:46:28.094104Z",
     "start_time": "2024-08-07T12:46:28.082830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Blob:\n",
    "    def __init__(self):\n",
    "        self.x = np.random.randint(0, SIZE)\n",
    "        self.y = np.random.randint(0, SIZE)\n",
    "    def __str__(self):\n",
    "        return f'{self.x}, {self.y}'\n",
    "    def __sub__(self, other):\n",
    "        return (self.x - other.x, self.y - other.y)\n",
    "    def action(self, choice):\n",
    "        if choice == 0:\n",
    "           self.move(x=1, y=1)\n",
    "        elif choice == 1:\n",
    "            self.move(x=-1, y=-1)\n",
    "        elif choice == 2:\n",
    "            self.move(x=-1, y=1)\n",
    "        elif choice == 3:\n",
    "            self.move(x=1, y=-1)\n",
    "    def move(self, x=False, y=False):\n",
    "        if not x:\n",
    "            self.x += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.x += x\n",
    "        if not y:\n",
    "            self.y += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.y += y\n",
    "        \n",
    "        if self.x < 0:\n",
    "            self.x = 0\n",
    "        elif self.x > SIZE-1:\n",
    "            self.x = SIZE-1\n",
    "        if self.y < 0:\n",
    "            self.y = 0\n",
    "        elif self.y > SIZE-1:\n",
    "            self.y = SIZE-1"
   ],
   "id": "125a2238a0002147",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Q table",
   "id": "7d62b67e7d67971"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if start_q_table is None:\n",
    "    q_table = {}\n",
    "    # (x1, y1), (x2, y2)\n",
    "    for x1 in range(-SIZE+1, SIZE):\n",
    "        for y1 in range(-SIZE+1, SIZE):\n",
    "            for x2 in range(-SIZE+1, SIZE):\n",
    "                for y2 in range(-SIZE+1, SIZE):\n",
    "                    q_table[((x1, y1),(x2,y2))] = [np.random.uniform(-5, 0) for i in range(4)]\n",
    "else:\n",
    "    with open(start_q_table, 'rb') as f:\n",
    "        q_table = pickle.load(f)\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(HM_EPISODES):\n",
    "    player = Blob()\n",
    "    food = Blob()\n",
    "    enemy = Blob()\n",
    "    if episode % SHOW_EVERY == 0:\n",
    "        print(f'on # {episode}, epsilon: {epsilon}')\n",
    "        print(f\"{SHOW_EVERY} ep mean: {np.mean(episode_rewards[-SHOW_EVERY:])}\")\n",
    "        show = True\n",
    "    else:\n",
    "        show = False\n",
    "    # frames of the episode\n",
    "    episode_reward = 0\n",
    "    for i in range(200):\n",
    "        obs = (player-food, player-enemy)\n",
    "        if np.random.random() > epsilon:\n",
    "            action = np.argmax(q_table[obs])\n",
    "        else:\n",
    "            action = np.random.randint(0, 4)\n",
    "            \n",
    "        player.action(action)\n",
    "        '''\n",
    "        MAYBE\n",
    "        enemy.move()\n",
    "        food.move()\n",
    "        '''"
   ],
   "id": "76c54768d04b930b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rewarding",
   "id": "d6dbeee34b128349"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if player.x == enemy.x and player.y == enemy.y:\n",
    "    reward =- ENEMY_PENALTY\n",
    "elif player.x == food.x and player.y == food.y:\n",
    "    reward = FOOD_REWARD\n",
    "else:\n",
    "    reward = -MOVE_PENALTY"
   ],
   "id": "3fcd336b141e99b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Q values and information",
   "id": "4d9b7a8a9e292075"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "new_obs = (player-food, player-enemy)\n",
    "# Max Q value for new obs\n",
    "max_future_q = np.max(q_table[new_obs])\n",
    "# Current Q for the chosen action\n",
    "current_q = np.max(q_table[obs][action])\n",
    "if reward == FOOD_REWARD:\n",
    "    new_q = FOOD_REWARD\n",
    "elif reward == -ENEMY_PENALTY:\n",
    "    new_q = - ENEMY_PENALTY\n",
    "else:\n",
    "    new_q = (1 - LEARNING_RATE) * current_q + LEARNING_RATE * (reward + DISCOUNT * max_future_q)\n",
    "q_table[obs][action] =  new_q"
   ],
   "id": "950c91d3ab862f82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Displaying the environment",
   "id": "9463e9bcf9551afa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if show:\n",
    "    env = np.zero((SIZE, SIZE, 3), dtype=np.uint8)\n",
    "    # Setting food, player and enemy tile ro their corresponding colors\n",
    "    env[food.x][food.y] = d[FOOD_N]\n",
    "    env[player.x][player.y] = d[PLAYER_N]\n",
    "    env[enemy.x][enemy.y] = d[ENEMY_N]\n",
    "    # Reading to RGB\n",
    "    img = Image.fromarray(env, 'RGB')\n",
    "    img = img.resize(300, 300)\n",
    "    cv2.show(''. np.array(img))\n",
    "    if reward == FOOD_REWARD or reward == -ENEMY_PENALTY:\n",
    "        if cv2.waitKey(500) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break"
   ],
   "id": "ccf0e11d79fa91d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
